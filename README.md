They say there is a fine line between love and hateâ€”but can a classifier detect it? This project examines hate speech directed at five Indian regional communities, focusing on the linguistic and cultural nuances that shape hostile expression. We constructed a manually labelled dataset and fine-tuned Indic MURIL to evaluate its ability to detect subtle, context-dependent hate in Reddit posts. Its performance was benchmarked against the base model and  alternative classifiers to assess true gains from fine-tuning. To test deployability, we evaluated robustness under distribution shift using a Twitter dataset and measured variation across labels from independent annotators, revealing the deep subjectivity embedded in hate-speech judgments. Topic analyses further uncovered recurring themes and gendered patterns in community-specific hate. Ultimately, our findings show that hate-speech detection cannot rely on universal models: meaningful reliability requires context-aware, culturally grounded classifiers rather than a one-size-fits-all approach.
